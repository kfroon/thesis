{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearnex import patch_sklearn \n",
    "patch_sklearn()\n",
    "from sklearn.svm import SVC\n",
    "from itertools import combinations\n",
    "from imports import *\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/kfroo/OneDrive/Desktop/Thesis/Breast Cancer Dataset/dataR2.csv\")\n",
    "target_variable = 'Classification'\n",
    "\n",
    "data['Classification'] = data['Classification'].map({1:0, 2:1})\n",
    "\n",
    "def preprocess(data):\n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1:]#.squeeze()\n",
    "    feature_names = X.columns\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(data.drop(columns = [target_variable], axis = 1))\n",
    "    X = pd.DataFrame(X, columns = feature_names)\n",
    "    data = pd.concat([X,y] ,axis = 1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=340, test_size=0.3)\n",
    "    return x_train, x_test, y_train, y_test, feature_names\n",
    "\n",
    "x_train, x_test, y_train, y_test, feature_names = preprocess(data)\n",
    "train_data = pd.concat([x_train, y_train], axis = 1)\n",
    "test_data = pd.concat([x_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini(y):\n",
    "    \"\"\"Calculate the Gini index for a given array of labels.\"\"\"\n",
    "    p = y.value_counts() / len(y)\n",
    "    gini = 1 - np.sum(p ** 2)\n",
    "    return gini\n",
    "    \n",
    "def gini_index(decision_function, y):\n",
    "    \"\"\"Calculate the Gini index for a given decision function and labels.\"\"\"\n",
    "    indices_less_zero = np.where(decision_function < 0)[0]\n",
    "    indices_greater_zero = np.where(decision_function > 0)[0]\n",
    "\n",
    "    g1 = y.iloc[indices_less_zero]\n",
    "    g2 = y.iloc[indices_greater_zero]\n",
    "\n",
    "    gini1 = calculate_gini(g1)\n",
    "    gini2 = calculate_gini(g2)\n",
    "\n",
    "    n = len(y)\n",
    "    gini_score = (len(g1) / n) * gini1 + (len(g2) / n) * gini2\n",
    "\n",
    "    return gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(decision_function, data):\n",
    "    \"\"\"Split the data into left and right data frames based on the decision function.\"\"\"\n",
    "    indices_less_zero = np.where(decision_function < 0)[0]\n",
    "    indices_greater_zero = np.where(decision_function > 0)[0]\n",
    "\n",
    "    left_data = data.iloc[indices_less_zero]\n",
    "    right_data = data.iloc[indices_greater_zero]\n",
    "    \n",
    "    return left_data, right_data\n",
    "    #return {'left':left_data, 'right':right_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this to concider 3 features \n",
    "\n",
    "def get_split(data, c):\n",
    "    c.self = c\n",
    "    \"\"\"Find the best Gini split for the given data.\"\"\"\n",
    "    best_gini = float('inf')\n",
    "    best_split = None\n",
    "\n",
    "    features = data.iloc[:, :-1]\n",
    "    target = data.iloc[:, -1]\n",
    "\n",
    "    #Generate all possible combinations of feature pairs\n",
    "    feature_pairs = list(combinations(features.columns, 3))\n",
    "    #decision_functions_array = []\n",
    "    svm_accs = []\n",
    "\n",
    "    for triple in feature_pairs:\n",
    "    #    # Select the pair of features\n",
    "        feature1, feature2, feature3 = triple\n",
    "        selected_features = features[[feature1, feature2, feature3]]\n",
    "        #print(selected_features)\n",
    "\n",
    "        # Train the SVM\n",
    "        svm = SVC(kernel='linear', C = c)\n",
    "        svm.fit(selected_features, target)\n",
    "\n",
    "        #Get accuracy of the svm on test_set\n",
    "        #y_pred_svm = svm.predict(x_test)\n",
    "        #svm_accs.append(f\"Accuracy: {metrics.accuracy_score(y_test, y_pred_svm)}\")\n",
    "\n",
    "        # Use the decision function to split the data\n",
    "        decision_function = svm.decision_function(selected_features)\n",
    "    \n",
    "        gini = gini_index(decision_function, target)\n",
    "        #all_gini.append(gini)\n",
    " \n",
    "        if gini < best_gini:\n",
    "            best_gini = gini\n",
    "            best_df = decision_function\n",
    "            best_svm = svm\n",
    "            best_split = {'feat1': selected_features.columns[0], \n",
    "                          'feat2': selected_features.columns[1],\n",
    "                          'feat3': selected_features.columns[2],\n",
    "                          'x1': np.around((best_svm.coef_[0][0]), 5), \n",
    "                          'x2': np.around((best_svm.coef_[0][1]), 5),\n",
    "                          'x3': np.around((best_svm.coef_[0][2]), 5),\n",
    "                          'intercept': np.around(best_svm.intercept_[0], 5)}\n",
    "            rule = f\"{best_split['x1']}*{best_split['feat1']} + {best_split['x2']}*{best_split['feat2']} + {best_split['x3']}*{best_split['feat3']} + {best_split['intercept']} < 0\"\n",
    "            #f\"{np.around((best_svm.coef_[0][0]), 5)}*{selected_features.columns[0]} + {np.around((best_svm.coef_[0][1]), 5)}*{selected_features.columns[1]} + {np.around(best_svm.intercept_[0], 5)} < 0 \"\n",
    "        \n",
    "        groups = test_split(best_df, data)\n",
    "\n",
    "    return {'best_split':best_split, 'split_rule': rule, 'best_df':best_df, 'best_svm':best_svm, 'groups':groups, 'svm_accs': svm_accs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal(subset):\n",
    "    outcomes = list((subset.iloc[:,-1]))\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_samples, depth, c):\n",
    "    c.self = c \n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "\n",
    "    #Check for no-split\n",
    "    if left.empty or right.empty:\n",
    "        node['left']  = node['right'] = to_terminal(pd.concat([left, right]))\n",
    "        return\n",
    "    \n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    \n",
    "    # process left child\n",
    "    if len(left) <= min_samples:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, c)\n",
    "        split(node['left'], max_depth, min_samples, depth+1)\n",
    "\n",
    "     # process right child\n",
    "    if len(right) <= min_samples:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right, c)\n",
    "        split(node['right'], max_depth, min_samples, depth+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size, c):\n",
    "   root = get_split(train)\n",
    "   split(root, max_depth, min_size, 0, c.self)\n",
    "   return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(instance, node):\n",
    "    if 'split_rule' not in node:\n",
    "        return node['left']  # Terminal node value\n",
    "    split_rule = node['split_rule']\n",
    "    print(split_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    " if isinstance(node, dict):\n",
    "    print(depth*'  ', f'Feature:{node[\"split_rule\"]}')\n",
    "    #print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "    print_tree(node['left'], depth+1)\n",
    "    print_tree(node['right'], depth+1)\n",
    " else:\n",
    "   print('%s[%s]' % ((depth*'  ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    feat1 = node['best_split']['feat1']\n",
    "    feat2 = node['best_split']['feat2']\n",
    "    x1 = node['best_split']['x1']\n",
    "    x2 = node['best_split']['x2']\n",
    "    intercept = node['best_split']['intercept']\n",
    "\n",
    "    score = x1 * row[feat1] + x2 * row[feat2] + intercept \n",
    "    if score < 0:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'depth': [i for i in range(1, 11)], \n",
    "        'samples': [i for i in range(5, 55, 10)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sd_accuracy(tree, test_data):\n",
    "    predictions_saved = []\n",
    "    for row in range(len(test_data)):\n",
    "        #print(test_data.iloc[row])\n",
    "        p = predict(tree, test_data.iloc[row])\n",
    "        predictions_saved.append(p)\n",
    "    y_pred = list(predictions_saved)\n",
    "    return round(accuracy_score(y_true, y_pred), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_split() missing 1 required positional argument: 'c'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[171], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m grid[\u001b[39m'\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m      5\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m         tree \u001b[39m=\u001b[39m build_tree(train_data, i, j, c \u001b[39m=\u001b[39;49m \u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m      7\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdepth: \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m and samples: \u001b[39m\u001b[39m{\u001b[39;00mj\u001b[39m}\u001b[39;00m\u001b[39m with accuracy: \u001b[39m\u001b[39m{\u001b[39;00msd_accuracy(tree,\u001b[39m \u001b[39mtest_data)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m         all_trees_in_grid\u001b[39m.\u001b[39mappend(tree)\n",
      "Cell \u001b[1;32mIn[170], line 3\u001b[0m, in \u001b[0;36mbuild_tree\u001b[1;34m(train, max_depth, min_size, c)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbuild_tree\u001b[39m(train, max_depth, min_size, c):\n\u001b[1;32m----> 3\u001b[0m    root \u001b[39m=\u001b[39m get_split(train)\n\u001b[0;32m      4\u001b[0m    split(root, max_depth, min_size, \u001b[39m0\u001b[39m, c\u001b[39m.\u001b[39mself)\n\u001b[0;32m      5\u001b[0m    \u001b[39mreturn\u001b[39;00m root\n",
      "\u001b[1;31mTypeError\u001b[0m: get_split() missing 1 required positional argument: 'c'"
     ]
    }
   ],
   "source": [
    "all_trees_in_grid = []\n",
    "y_true = list(test_data.Classification)\n",
    "for i in grid['depth']:\n",
    "    for j in grid['samples']:\n",
    "        try:\n",
    "            tree = build_tree(train_data, i, j, c = 0.1)\n",
    "            print(f\"depth: {i} and samples: {j} with accuracy: {sd_accuracy(tree, test_data)}\")\n",
    "            all_trees_in_grid.append(tree)\n",
    "        except ValueError:\n",
    "            print(f\"depth: {i} and samples: {j}, doesn't work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature:1.62404*Glucose + 1.47196*Resistin + -0.40871*MCP.1 + 0.92703 < 0\n",
      "   Feature:-0.43586*BMI + 0.78886*Insulin + 1.75782*Resistin + -0.29836 < 0\n",
      "     Feature:-0.0002*Age + 2e-05*BMI + 0.00168*Glucose + -0.99932 < 0\n",
      "      [0]\n",
      "      [0]\n",
      "    [1]\n",
      "   Feature:-0.00011*Age + -6e-05*BMI + 0.00026*Glucose + 1.00002 < 0\n",
      "    [1]\n",
      "    [1]\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(train_data, 4, 5)\n",
    "#print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(test_data.Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sd_accuracy(tree, test_data):\n",
    "    predictions_saved = []\n",
    "    for row in range(len(test_data)):\n",
    "        #print(test_data.iloc[row])\n",
    "        p = predict(tree, test_data.iloc[row])\n",
    "        predictions_saved.append(p)\n",
    "    y_pred = list(predictions_saved)\n",
    "    return round(accuracy_score(y_true, y_pred), 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.714286, f1_score: 0.772727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"accuracy: {round(accuracy_score(y_true, y_pred), 6)}, f1_score: {round(f1_score(y_true, y_pred), 6)}\")\n",
    "\n",
    "#accuracy: 0.714286, f1_score: 0.772727"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
