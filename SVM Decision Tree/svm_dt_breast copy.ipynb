{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from itertools import combinations\n",
    "from imports import *\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/kfroo/OneDrive/Desktop/Thesis/pulsing stars/HTRU_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['140.5625', '55.68378214', '-0.234571412', '-0.699648398',\n",
       "       '3.199832776', '19.11042633', '7.975531794', '74.24222492', '0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.columns(['mean', 'std_dev', 'Excess kurtosis of the integrated profile.\n",
    "\t4. Skewness of the integrated profile.\n",
    "\t5. Mean of the DM-SNR curve.\n",
    "\t6. Standard deviation of the DM-SNR curve.\n",
    "\t7. Excess kurtosis of the DM-SNR curve.\n",
    "\t8. Skewness of the DM-SNR curve])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Classification'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\kfroo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\kfroo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kfroo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Classification'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mC:/Users/kfroo/OneDrive/Desktop/Thesis/pulsing stars/HTRU_2.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m target_variable \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mClassification\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 10\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mClassification\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39;49m\u001b[39mClassification\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmap({\u001b[39m1\u001b[39m:\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m:\u001b[39m1\u001b[39m})\n\u001b[0;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess\u001b[39m(data):\n\u001b[0;32m     13\u001b[0m     X \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39miloc[:,:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kfroo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\kfroo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Classification'"
     ]
    }
   ],
   "source": [
    "\n",
    "target_variable = 'Classification'\n",
    "\n",
    "data['Classification'] = data['Classification'].map({1:0, 2:1})\n",
    "\n",
    "def preprocess(data):\n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1:]#.squeeze()\n",
    "    feature_names = X.columns\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(data.drop(columns = [target_variable], axis = 1))\n",
    "    X = pd.DataFrame(X, columns = feature_names)\n",
    "    data = pd.concat([X,y] ,axis = 1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=390, test_size=0.3)\n",
    "    return x_train, x_test, y_train, y_test, feature_names\n",
    "\n",
    "x_train, x_test, y_train, y_test, feature_names = preprocess(data)\n",
    "train_data = pd.concat([x_train, y_train], axis = 1)\n",
    "test_data = pd.concat([x_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini(y):\n",
    "    \"\"\"Calculate the Gini index for a given array of labels.\"\"\"\n",
    "    p = y.value_counts() / len(y)\n",
    "    gini = 1 - np.sum(p ** 2)\n",
    "    return gini\n",
    "    \n",
    "def gini_index(decision_function, y):\n",
    "    \"\"\"Calculate the Gini index for a given decision function and labels.\"\"\"\n",
    "    indices_less_zero = np.where(decision_function < 0)[0]\n",
    "    indices_greater_zero = np.where(decision_function > 0)[0]\n",
    "\n",
    "    g1 = y.iloc[indices_less_zero]\n",
    "    g2 = y.iloc[indices_greater_zero]\n",
    "\n",
    "    gini1 = calculate_gini(g1)\n",
    "    gini2 = calculate_gini(g2)\n",
    "\n",
    "    n = len(y)\n",
    "    gini_score = (len(g1) / n) * gini1 + (len(g2) / n) * gini2\n",
    "\n",
    "    return gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(decision_function, data):\n",
    "    \"\"\"Split the data into left and right data frames based on the decision function.\"\"\"\n",
    "    indices_less_zero = np.where(decision_function < 0)[0]\n",
    "    indices_greater_zero = np.where(decision_function > 0)[0]\n",
    "\n",
    "    left_data = data.iloc[indices_less_zero]\n",
    "    right_data = data.iloc[indices_greater_zero]\n",
    "    \n",
    "    return left_data, right_data\n",
    "    #return {'left':left_data, 'right':right_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(data):\n",
    "    \"\"\"Find the best Gini split for the given data.\"\"\"\n",
    "    best_gini = float('inf')\n",
    "    best_split = None\n",
    "\n",
    "    features = data.iloc[:, :-1]\n",
    "    target = data.iloc[:, -1]\n",
    "\n",
    "    #Generate all possible combinations of feature pairs\n",
    "    feature_pairs = list(combinations(features.columns, 2))\n",
    "    #decision_functions_array = []\n",
    "\n",
    "    for pair in feature_pairs:\n",
    "    #    # Select the pair of features\n",
    "        feature1, feature2 = pair\n",
    "        selected_features = features[[feature1, feature2]]\n",
    "        #print(selected_features)\n",
    "\n",
    "        # Train the SVM\n",
    "        svm = SVC(kernel='linear', C = 10)\n",
    "        svm.fit(selected_features, target)\n",
    "\n",
    "        # Use the decision function to split the data\n",
    "        decision_function = svm.decision_function(selected_features)\n",
    "    \n",
    "        gini = gini_index(decision_function, target)\n",
    "        #all_gini.append(gini)\n",
    " \n",
    "        if gini < best_gini:\n",
    "            best_gini = gini\n",
    "            best_df = decision_function\n",
    "            best_svm = svm\n",
    "            best_split = {'feat1': selected_features.columns[0], \n",
    "                          'feat2': selected_features.columns[1],\n",
    "                          'x1': np.around((best_svm.coef_[0][0]), 5), \n",
    "                          'x2': np.around((best_svm.coef_[0][1]), 5),\n",
    "                          'intercept': np.around(best_svm.intercept_[0], 5)}\n",
    "            rule = f\"{best_split['x1']}*{best_split['feat1']} + {best_split['x2']}*{best_split['feat2']} + {best_split['intercept']} < 0\"\n",
    "            #f\"{np.around((best_svm.coef_[0][0]), 5)}*{selected_features.columns[0]} + {np.around((best_svm.coef_[0][1]), 5)}*{selected_features.columns[1]} + {np.around(best_svm.intercept_[0], 5)} < 0 \"\n",
    "        \n",
    "        groups = test_split(best_df, data)\n",
    "\n",
    "    return {'best_split':best_split, 'split_rule': rule, 'best_df':best_df, 'best_svm':best_svm, 'groups':groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal(subset):\n",
    "    outcomes = list((subset.iloc[:,-1]))\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_samples, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "\n",
    "    #Check for no-split\n",
    "    if left.empty or right.empty:\n",
    "        node['left']  = node['right'] = to_terminal(pd.concat([left, right]))\n",
    "        return\n",
    "    \n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    \n",
    "    # process left child\n",
    "    if len(left) <= min_samples:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_samples, depth+1)\n",
    "\n",
    "     # process right child\n",
    "    if len(right) <= min_samples:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_samples, depth+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "   root = get_split(train)\n",
    "   split(root, max_depth, min_size, 0)\n",
    "   return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(instance, node):\n",
    "    if 'split_rule' not in node:\n",
    "        return node['left']  # Terminal node value\n",
    "    split_rule = node['split_rule']\n",
    "    print(split_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    " if isinstance(node, dict):\n",
    "    print(depth*'  ', f'Feature:{node[\"split_rule\"]}')\n",
    "    #print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "    print_tree(node['left'], depth+1)\n",
    "    print_tree(node['right'], depth+1)\n",
    " else:\n",
    "   print('%s[%s]' % ((depth*'  ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    feat1 = node['best_split']['feat1']\n",
    "    feat2 = node['best_split']['feat2']\n",
    "    x1 = node['best_split']['x1']\n",
    "    x2 = node['best_split']['x2']\n",
    "    intercept = node['best_split']['intercept']\n",
    "\n",
    "    score = x1 * row[feat1] + x2 * row[feat2] + intercept \n",
    "    if score < 0:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature:-0.18402*Age + 2.74401*Glucose + 0.60776 < 0\n",
      "   Feature:-0.41152*Leptin + 1.29267*Resistin + -0.80103 < 0\n",
      "     Feature:-7e-05*Age + -9e-05*BMI + -1.00003 < 0\n",
      "      [0]\n",
      "      [0]\n",
      "    [1]\n",
      "  [1]\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(train_data, 3, 45)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(test_data.Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_saved = []\n",
    "for row in range(len(test_data)):\n",
    "    #print(test_data.iloc[row])\n",
    "    p = predict(tree, test_data.iloc[row])\n",
    "    predictions_saved.append(p)\n",
    "y_pred = list(predictions_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
