{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from itertools import combinations\n",
    "from imports import *\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/kfroo/OneDrive/Desktop/Thesis/Breast Cancer Dataset/dataR2.csv\")\n",
    "target_variable = 'Classification'\n",
    "\n",
    "data['Classification'] = data['Classification'].map({1:0, 2:1})\n",
    "\n",
    "def preprocess(data):\n",
    "    X = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1:]#.squeeze()\n",
    "    feature_names = X.columns\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(data.drop(columns = [target_variable], axis = 1))\n",
    "    X = pd.DataFrame(X, columns = feature_names)\n",
    "    data = pd.concat([X,y] ,axis = 1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=390, test_size=0.3)\n",
    "    return x_train, x_test, y_train, y_test, feature_names\n",
    "\n",
    "x_train, x_test, y_train, y_test, feature_names = preprocess(data)\n",
    "train_data = pd.concat([x_train, y_train], axis = 1)\n",
    "test_data = pd.concat([x_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini(y):\n",
    "    \"\"\"Calculate the Gini index for a given array of labels.\"\"\"\n",
    "    p = y.value_counts() / len(y)\n",
    "    gini = 1 - np.sum(p ** 2)\n",
    "    return gini\n",
    "    \n",
    "def gini_index(decision_function, y):\n",
    "    \"\"\"Calculate the Gini index for a given decision function and labels.\"\"\"\n",
    "    indices_less_zero = np.where(decision_function < 0)[0]\n",
    "    indices_greater_zero = np.where(decision_function > 0)[0]\n",
    "\n",
    "    g1 = y.iloc[indices_less_zero]\n",
    "    g2 = y.iloc[indices_greater_zero]\n",
    "\n",
    "    gini1 = calculate_gini(g1)\n",
    "    gini2 = calculate_gini(g2)\n",
    "\n",
    "    n = len(y)\n",
    "    gini_score = (len(g1) / n) * gini1 + (len(g2) / n) * gini2\n",
    "\n",
    "    return gini_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(decision_function, data):\n",
    "    \"\"\"Split the data into left and right data frames based on the decision function.\"\"\"\n",
    "    indices_less_zero = np.where(decision_function < 0)[0]\n",
    "    indices_greater_zero = np.where(decision_function > 0)[0]\n",
    "\n",
    "    left_data = data.iloc[indices_less_zero]\n",
    "    right_data = data.iloc[indices_greater_zero]\n",
    "    \n",
    "    return left_data, right_data\n",
    "    #return {'left':left_data, 'right':right_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(data):\n",
    "    \"\"\"Find the best Gini split for the given data.\"\"\"\n",
    "    best_gini = float('inf')\n",
    "    best_split = None\n",
    "\n",
    "    features = data.iloc[:, :-1]\n",
    "    target = data.iloc[:, -1]\n",
    "\n",
    "    #Generate all possible combinations of feature pairs\n",
    "    feature_pairs = list(combinations(features.columns, 2))\n",
    "    #decision_functions_array = []\n",
    "\n",
    "    for pair in feature_pairs:\n",
    "    #    # Select the pair of features\n",
    "        feature1, feature2 = pair\n",
    "        selected_features = features[[feature1, feature2]]\n",
    "        #print(selected_features)\n",
    "\n",
    "        # Train the SVM\n",
    "        svm = SVC(kernel='linear', C = 10)\n",
    "        svm.fit(selected_features, target)\n",
    "\n",
    "        # Use the decision function to split the data\n",
    "        decision_function = svm.decision_function(selected_features)\n",
    "    \n",
    "        gini = gini_index(decision_function, target)\n",
    "        #all_gini.append(gini)\n",
    " \n",
    "        if gini < best_gini:\n",
    "            best_gini = gini\n",
    "            best_df = decision_function\n",
    "            best_svm = svm\n",
    "            best_split = {'feat1': selected_features.columns[0], \n",
    "                          'feat2': selected_features.columns[1],\n",
    "                          'x1': np.around((best_svm.coef_[0][0]), 5), \n",
    "                          'x2': np.around((best_svm.coef_[0][1]), 5),\n",
    "                          'intercept': np.around(best_svm.intercept_[0], 5)}\n",
    "            rule = f\"{best_split['x1']}*{best_split['feat1']} + {best_split['x2']}*{best_split['feat2']} + {best_split['intercept']} < 0\"\n",
    "            #f\"{np.around((best_svm.coef_[0][0]), 5)}*{selected_features.columns[0]} + {np.around((best_svm.coef_[0][1]), 5)}*{selected_features.columns[1]} + {np.around(best_svm.intercept_[0], 5)} < 0 \"\n",
    "        \n",
    "        groups = test_split(best_df, data)\n",
    "\n",
    "    return {'best_split':best_split, 'split_rule': rule, 'best_df':best_df, 'best_svm':best_svm, 'groups':groups}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal(subset):\n",
    "    outcomes = list((subset.iloc[:,-1]))\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_samples, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "\n",
    "    #Check for no-split\n",
    "    if left.empty or right.empty:\n",
    "        node['left']  = node['right'] = to_terminal(pd.concat([left, right]))\n",
    "        return\n",
    "    \n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    \n",
    "    # process left child\n",
    "    if len(left) <= min_samples:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_samples, depth+1)\n",
    "\n",
    "     # process right child\n",
    "    if len(right) <= min_samples:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_samples, depth+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a decision tree\n",
    "def build_tree(train, max_depth, min_size):\n",
    "   root = get_split(train)\n",
    "   split(root, max_depth, min_size, 0)\n",
    "   return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def predict(instance, node):\n",
    "#    if 'split_rule' not in node:\n",
    "#        return node['left']  # Terminal node value\n",
    "#    split_rule = node['split_rule']\n",
    "#    print(split_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a decision tree\n",
    "def print_tree(node, depth=0):\n",
    " if isinstance(node, dict):\n",
    "    print(depth*'  ', f'Feature:{node[\"split_rule\"]}')\n",
    "    #print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "    print_tree(node['left'], depth+1)\n",
    "    print_tree(node['right'], depth+1)\n",
    " else:\n",
    "   print('%s[%s]' % ((depth*'  ', node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with a decision tree\n",
    "def predict(node, row):\n",
    "    feat1 = node['best_split']['feat1']\n",
    "    feat2 = node['best_split']['feat2']\n",
    "    x1 = node['best_split']['x1']\n",
    "    x2 = node['best_split']['x2']\n",
    "    intercept = node['best_split']['intercept']\n",
    "\n",
    "    score = x1 * row[feat1] + x2 * row[feat2] + intercept \n",
    "    if score < 0:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature:-0.18402*Age + 2.74401*Glucose + 0.60776 < 0\n",
      "   Feature:-0.41152*Leptin + 1.29267*Resistin + -0.80103 < 0\n",
      "     Feature:-7e-05*Age + -9e-05*BMI + -1.00003 < 0\n",
      "      [0]\n",
      "      [0]\n",
      "    [1]\n",
      "   Feature:-3.61012*BMI + 1.51547*Glucose + 5.43427 < 0\n",
      "    [0]\n",
      "     Feature:9e-05*Age + -0.00042*BMI + 1.00043 < 0\n",
      "      [1]\n",
      "      [1]\n"
     ]
    }
   ],
   "source": [
    "tree = build_tree(train_data, 4, 10)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(test_data.Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_saved = []\n",
    "for row in range(len(test_data)):\n",
    "    #print(test_data.iloc[row])\n",
    "    p = predict(tree, test_data.iloc[row])\n",
    "    predictions_saved.append(p)\n",
    "y_pred = list(predictions_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
